{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def pprint(o):\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent and Entity Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'data/nlu_data.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = '''\n",
    "## intent:greet\n",
    "- hi\n",
    "- hello\n",
    "- hi, my name is [Jack](PERSON)\n",
    "- hello, my name is [Jack](PERSON)\n",
    "- hey\n",
    "\n",
    "## intent:tax_due_dates\n",
    "- When are property taxes due?\n",
    "- When do I have to pay my taxes?\n",
    "- tax due dates?\n",
    "- where are taxes due?\n",
    "- when do I pay taxes?\n",
    "- are taxes due soon?\n",
    "- find property tax due dates\n",
    "- property tax due dates\n",
    "- property taxes due\n",
    "- how often do I have to pay my taxes?\n",
    "- how many times do I pay taxes?\n",
    "- when can I pay my taxes?\n",
    "- when do I pay my taxes?\n",
    "- when do I pay property taxes?\n",
    "\n",
    "## intent:goodbye\n",
    "- Bye\n",
    "- goodbye\n",
    "- peace\n",
    "- later hater\n",
    "- thank you, bye\n",
    "- see you later\n",
    "- see you soon\n",
    "\n",
    "## intent:thankyou\n",
    "- Thank you!\n",
    "- thanks\n",
    "- thank you\n",
    "- I appreciate it\n",
    "- gracias\n",
    "'''\n",
    "\n",
    "%store nlu_md > data/nlu_data.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'config' (str) to file 'nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "config = '''\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: 'nlp_spacy'\n",
    "- name: 'tokenizer_spacy'\n",
    "- name: 'ner_spacy'\n",
    "- name: 'intent_featurizer_spacy'\n",
    "- name: 'intent_classifier_sklearn'\n",
    "'''\n",
    "\n",
    "%store config > nlu_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Rasa NLU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.training_data.loading:Training data format of data/nlu_data.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 31 (4 distinct intents)\n",
      "\t- Found intents: 'goodbye', 'tax_due_dates', 'thankyou', 'greet'\n",
      "\t- entity examples: 2 (1 distinct entities)\n",
      "\t- found entities: 'PERSON'\n",
      "\n",
      "INFO:rasa_nlu.utils.spacy_utils:Trying to load spacy model with name 'en'\n",
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.model:Starting to train component nlp_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component tokenizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component ner_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_featurizer_spacy\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Starting to train component intent_classifier_sklearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "INFO:rasa_nlu.model:Finished training component.\n",
      "INFO:rasa_nlu.model:Successfully saved model into 'C:\\Users\\vanguiano\\Documents\\Projects\\conversational-interface\\models\\nlu\\default\\current'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "training_data = load_data(\"data/nlu_data.md\")\n",
    "\n",
    "trainer = Trainer(config.load(\"nlu_config.yml\"))\n",
    "\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.\n",
      "INFO:rasa_nlu.training_data.loading:Training data format of data/nlu_data.md is md\n",
      "INFO:rasa_nlu.training_data.training_data:Training data stats: \n",
      "\t- intent examples: 31 (4 distinct intents)\n",
      "\t- Found intents: 'goodbye', 'tax_due_dates', 'thankyou', 'greet'\n",
      "\t- entity examples: 2 (1 distinct entities)\n",
      "\t- found entities: 'PERSON'\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Intent evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Intent Evaluation: Only considering those 31 examples that have a defined intent out of 31 examples\n",
      "INFO:rasa_nlu.evaluate:F1-Score:  1.0\n",
      "INFO:rasa_nlu.evaluate:Precision: 1.0\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  1.0\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      goodbye       1.00      1.00      1.00         7\n",
      "        greet       1.00      1.00      1.00         5\n",
      "tax_due_dates       1.00      1.00      1.00        14\n",
      "     thankyou       1.00      1.00      1.00         5\n",
      "\n",
      "  avg / total       1.00      1.00      1.00        31\n",
      "\n",
      "INFO:rasa_nlu.evaluate:Confusion matrix, without normalization: \n",
      "[[ 7  0  0  0]\n",
      " [ 0  5  0  0]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0  0  5]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAFVCAYAAABcl7BDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMysMJy0zMysMJy0zMysMP4/dVimZmsApwQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26ec7c45860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_nlu.evaluate:Entity evaluation results:\n",
      "INFO:rasa_nlu.evaluate:Evaluation for entity extractor: ner_spacy \n",
      "INFO:rasa_nlu.evaluate:F1-Score:  1.0\n",
      "INFO:rasa_nlu.evaluate:Precision: 1.0\n",
      "INFO:rasa_nlu.evaluate:Accuracy:  1.0\n",
      "INFO:rasa_nlu.evaluate:Classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     PERSON       1.00      1.00      1.00         2\n",
      "  no_entity       1.00      1.00      1.00       124\n",
      "\n",
      "avg / total       1.00      1.00      1.00       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu_data.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories' (str) to file 'data/stories.md'.\n"
     ]
    }
   ],
   "source": [
    "stories = '''\n",
    "## tax_due_dates_1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* tax_due_dates\n",
    "  - action_request_info\n",
    "* thankyou\n",
    "  -utter_youre_welcome\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## tax_due_dates_3\n",
    "* greet\n",
    "  - utter_greet\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## tax_due_dates_4\n",
    "* greet\n",
    "  - utter_greet\n",
    "* tax_due_dates\n",
    "  - action_request_info\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "'''\n",
    "\n",
    "%store stories > data/stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain' (str) to file 'domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain = '''\n",
    "intents:\n",
    "  - tax_due_dates\n",
    "  - greet\n",
    "  - goodbye\n",
    "  - thankyou\n",
    "\n",
    "actions:\n",
    "  - utter_greet\n",
    "  - utter_goodbye\n",
    "  - utter_youre_welcome\n",
    "  - actions.ActionRequestInfo\n",
    "\n",
    "entities:\n",
    "  - PERSON\n",
    "  \n",
    "slots:\n",
    "  trial:\n",
    "    type: text\n",
    "  PERSON:\n",
    "    type: text\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "    - \"Hi!\"\n",
    "    - \"Hello, {PERSON}!\"\n",
    "    - \"Hi {PERSON}, it's great to hear from you!\"\n",
    "    - \"Hey {PERSON}, how can I help you?\"\n",
    "\n",
    "  utter_goodbye:\n",
    "    - \"Bye!\"\n",
    "    - \"I hope you had a good experience today!\"\n",
    "    - \"See you soon!\"\n",
    "    - \"Talk to you later!\"\n",
    "    - \"Goodbye.\"\n",
    "\n",
    "  utter_youre_welcome:\n",
    "    - \"You're welcome, {PERSON}!\"\n",
    "    - \"No problem {PERSON}, I'm happy to help.\"\n",
    "    - \"You're welcome.\"\n",
    "    - \"No problem!\"\n",
    "'''\n",
    "\n",
    "%store domain > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:apscheduler.scheduler:Scheduler started\n",
      "C:\\Users\\vanguiano\\Anaconda3\\lib\\site-packages\\pykwalify\\core.py:99: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  data = yaml.load(stream)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 185.38it/s, # trackers=1]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "('requires pygraphviz ', 'http://pygraphviz.github.io/')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_agraph.py\u001b[0m in \u001b[0;36mto_agraph\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mpygraphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f3988886ce48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"domain.yml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/stories.md\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"story_graph.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"story_graph.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\rasa_core\\agent.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(self, resource_name, output_file, max_history, nlu_training_data, should_merge_nodes, fontsize)\u001b[0m\n\u001b[0;32m    359\u001b[0m         visualize_stories(story_steps, self.domain, output_file, max_history,\n\u001b[0;32m    360\u001b[0m                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpreter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlu_training_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                           should_merge_nodes, fontsize)\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_ensure_agent_is_prepared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\rasa_core\\training\\visualization.py\u001b[0m in \u001b[0;36mvisualize_stories\u001b[1;34m(story_steps, domain, output_file, max_history, interpreter, nlu_training_data, should_merge_nodes, fontsize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mpersist_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\rasa_core\\training\\visualization.py\u001b[0m in \u001b[0;36mpersist_graph\u001b[1;34m(G, output_file)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx_agraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_agraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# convert to a graphviz graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     A.layout(\"dot\", args=\"-Goverlap=false -Gsplines=true -Gconcentrate=true \"\n\u001b[0;32m    222\u001b[0m                          \"-Gfontname=typewriter\")\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_agraph.py\u001b[0m in \u001b[0;36mto_agraph\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         raise ImportError('requires pygraphviz ',\n\u001b[1;32m--> 140\u001b[1;33m                           'http://pygraphviz.github.io/')\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[0mdirected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mstrict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_selfloops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: ('requires pygraphviz ', 'http://pygraphviz.github.io/')"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent(\"domain.yml\")\n",
    "agent.visualize(\"data/stories.md\", \"story_graph.png\", max_history=2)\n",
    "Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanguiano\\Anaconda3\\lib\\site-packages\\pykwalify\\core.py:99: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  data = yaml.load(stream)\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 165.61it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 320.50it/s, # trackers=3]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 179.46it/s, # trackers=4]\n",
      "Processed Story Blocks: 100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 144.71it/s, # trackers=4]\n",
      "INFO:rasa_core.featurizers:Creating states and action examples from collected trackers (by MaxHistoryTrackerFeaturizer)...\n",
      "Processed trackers: 100%|████████████████████████████████████████████████| 38/38 [00:02<00:00, 13.44it/s, # actions=23]\n",
      "INFO:rasa_core.featurizers:Created 23 action examples.\n",
      "Processed actions: 23it [00:00, 159.31it/s, # examples=23]\n",
      "INFO:rasa_core.policies.memoization:Memorized 23 unique action examples.\n",
      "INFO:rasa_core.featurizers:Creating states and action examples from collected trackers (by MaxHistoryTrackerFeaturizer)...\n",
      "Processed trackers: 100%|████████████████████████████████████████████████| 38/38 [00:02<00:00, 14.38it/s, # actions=23]\n",
      "INFO:rasa_core.featurizers:Created 23 action examples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_4 (Masking)          (None, 5, 14)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                6016      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 231       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 6,247\n",
      "Trainable params: 6,247\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Fitting model with 23 total samples and a validation split of 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 2s 66ms/step - loss: 1.9344 - acc: 0.0870\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 0s 438us/step - loss: 1.9053 - acc: 0.1304\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 0s 353us/step - loss: 1.9142 - acc: 0.1739\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.8865 - acc: 0.3043\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 0s 583us/step - loss: 1.8861 - acc: 0.3913\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 0s 262us/step - loss: 1.8900 - acc: 0.3478\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 0s 475us/step - loss: 1.8544 - acc: 0.5652\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 0s 179us/step - loss: 1.8357 - acc: 0.4348\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 0s 0us/step - loss: 1.8377 - acc: 0.4783\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 0s 694us/step - loss: 1.8399 - acc: 0.5217\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.8235 - acc: 0.4783\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 0s 401us/step - loss: 1.7816 - acc: 0.5217\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.7649 - acc: 0.5217\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.7676 - acc: 0.5217\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 0s 446us/step - loss: 1.7674 - acc: 0.5217\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.7416 - acc: 0.5217\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 0s 422us/step - loss: 1.7103 - acc: 0.5217\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 0s 247us/step - loss: 1.7407 - acc: 0.5217\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 0s 730us/step - loss: 1.7150 - acc: 0.5217\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 0s 113us/step - loss: 1.7004 - acc: 0.5217\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 0s 0us/step - loss: 1.6642 - acc: 0.5217\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.6857 - acc: 0.5217\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 0s 490us/step - loss: 1.6579 - acc: 0.5217\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 0s 401us/step - loss: 1.6582 - acc: 0.5217\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 0s 441us/step - loss: 1.6301 - acc: 0.5217\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 0s 396us/step - loss: 1.5831 - acc: 0.5217\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 0s 263us/step - loss: 1.6152 - acc: 0.5217\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.5830 - acc: 0.5217\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 0s 339us/step - loss: 1.5595 - acc: 0.5217\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.6080 - acc: 0.5217\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 0s 522us/step - loss: 1.5546 - acc: 0.5217\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.5155 - acc: 0.5217\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.5073 - acc: 0.5217\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 0s 398us/step - loss: 1.5157 - acc: 0.5217\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 0s 354us/step - loss: 1.5037 - acc: 0.5217\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.4889 - acc: 0.5217\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 0s 383us/step - loss: 1.4710 - acc: 0.5217\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 0s 223us/step - loss: 1.4608 - acc: 0.5217\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 0s 350us/step - loss: 1.4660 - acc: 0.5217\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.4591 - acc: 0.5217\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.4272 - acc: 0.5217\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.4800 - acc: 0.5217\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 0s 275us/step - loss: 1.4199 - acc: 0.5217\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 0s 218us/step - loss: 1.4100 - acc: 0.5217\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 0s 402us/step - loss: 1.4650 - acc: 0.5217\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 0s 376us/step - loss: 1.4297 - acc: 0.5217\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 0s 510us/step - loss: 1.4192 - acc: 0.5217\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 0s 347us/step - loss: 1.4210 - acc: 0.5217\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 0s 395us/step - loss: 1.4126 - acc: 0.5217\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 0s 217us/step - loss: 1.3831 - acc: 0.5217\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.3867 - acc: 0.5217\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.4151 - acc: 0.5217\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.3895 - acc: 0.5217\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.3490 - acc: 0.5217\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.3785 - acc: 0.5217\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 0s 522us/step - loss: 1.3572 - acc: 0.5217\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 0s 217us/step - loss: 1.3579 - acc: 0.5217\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 0s 263us/step - loss: 1.3850 - acc: 0.5217\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.3151 - acc: 0.5217\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 0s 209us/step - loss: 1.3477 - acc: 0.5217\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 0s 282us/step - loss: 1.3198 - acc: 0.5217\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 0s 481us/step - loss: 1.3511 - acc: 0.5217\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 0s 363us/step - loss: 1.3533 - acc: 0.5217\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.2825 - acc: 0.5217\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 0s 219us/step - loss: 1.3757 - acc: 0.5217\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.3457 - acc: 0.5217\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.3034 - acc: 0.5217\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 0s 397us/step - loss: 1.3007 - acc: 0.5217\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 0s 271us/step - loss: 1.3049 - acc: 0.5217\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 0s 401us/step - loss: 1.3113 - acc: 0.5217\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 0s 268us/step - loss: 1.2822 - acc: 0.5217\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 0s 410us/step - loss: 1.3241 - acc: 0.5217\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 0s 227us/step - loss: 1.2798 - acc: 0.5217\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 0s 336us/step - loss: 1.2672 - acc: 0.5217\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.2893 - acc: 0.5217\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 0s 276us/step - loss: 1.2942 - acc: 0.5217\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 0s 174us/step - loss: 1.2458 - acc: 0.5217\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 0s 385us/step - loss: 1.2839 - acc: 0.5217\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 0s 404us/step - loss: 1.3094 - acc: 0.5217\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 0s 328us/step - loss: 1.2788 - acc: 0.5217\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 0s 353us/step - loss: 1.2581 - acc: 0.5217\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 0s 335us/step - loss: 1.2399 - acc: 0.5217\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 0s 437us/step - loss: 1.2539 - acc: 0.5217\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 0s 359us/step - loss: 1.2389 - acc: 0.5217\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 0s 130us/step - loss: 1.2710 - acc: 0.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "23/23 [==============================] - 0s 342us/step - loss: 1.2254 - acc: 0.5217\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 0s 398us/step - loss: 1.2581 - acc: 0.5217\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 0s 310us/step - loss: 1.2093 - acc: 0.5217\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 0s 280us/step - loss: 1.2392 - acc: 0.5217\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 0s 468us/step - loss: 1.2258 - acc: 0.5217\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 0s 618us/step - loss: 1.2202 - acc: 0.5217\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 0s 475us/step - loss: 1.2510 - acc: 0.5217\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 0s 389us/step - loss: 1.2005 - acc: 0.5217\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 0s 304us/step - loss: 1.2473 - acc: 0.5217\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 1.2095 - acc: 0.5217\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 0s 233us/step - loss: 1.2302 - acc: 0.5217\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 0s 411us/step - loss: 1.2169 - acc: 0.5217\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 0s 389us/step - loss: 1.2014 - acc: 0.5217\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 0s 505us/step - loss: 1.1979 - acc: 0.5217\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 0s 452us/step - loss: 1.1365 - acc: 0.5217\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 0s 377us/step - loss: 1.1692 - acc: 0.5217\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 0s 221us/step - loss: 1.1833 - acc: 0.5217\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.1658 - acc: 0.5217\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 0s 241us/step - loss: 1.1613 - acc: 0.5217\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 0s 315us/step - loss: 1.1488 - acc: 0.5217\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 0s 483us/step - loss: 1.1583 - acc: 0.5217\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 0s 380us/step - loss: 1.1656 - acc: 0.5217\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 0s 353us/step - loss: 1.1505 - acc: 0.5217\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 0s 290us/step - loss: 1.1167 - acc: 0.5217\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 0s 233us/step - loss: 1.1570 - acc: 0.5217\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 0s 390us/step - loss: 1.1187 - acc: 0.5217\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 0s 362us/step - loss: 1.1077 - acc: 0.5217\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 0s 417us/step - loss: 1.0753 - acc: 0.5217\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 0s 339us/step - loss: 1.1175 - acc: 0.5652\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 0s 277us/step - loss: 1.0840 - acc: 0.5652\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 0s 396us/step - loss: 1.1179 - acc: 0.5217\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 0s 401us/step - loss: 1.0779 - acc: 0.5652\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 0s 392us/step - loss: 1.1172 - acc: 0.5217\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 1.1112 - acc: 0.5652\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 0s 441us/step - loss: 1.0450 - acc: 0.6087\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 0s 396us/step - loss: 1.0944 - acc: 0.5217\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 0s 222us/step - loss: 1.1023 - acc: 0.5217\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 1.1025 - acc: 0.5217\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 0s 275us/step - loss: 1.0525 - acc: 0.5652\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 0s 325us/step - loss: 1.0926 - acc: 0.5652\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 0s 289us/step - loss: 1.0777 - acc: 0.6087\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 0s 297us/step - loss: 1.0132 - acc: 0.5652\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 0s 424us/step - loss: 1.0354 - acc: 0.5217\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 0s 239us/step - loss: 1.0093 - acc: 0.6087\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 0s 396us/step - loss: 0.9833 - acc: 0.6087\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 0s 308us/step - loss: 0.9818 - acc: 0.6087\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 0s 254us/step - loss: 1.0561 - acc: 0.5217\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 0s 345us/step - loss: 0.9873 - acc: 0.6087\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 0s 315us/step - loss: 1.0321 - acc: 0.6522\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 0s 261us/step - loss: 1.0617 - acc: 0.6087\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 0s 341us/step - loss: 0.9971 - acc: 0.5652\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 0s 259us/step - loss: 0.9410 - acc: 0.6087\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 0s 413us/step - loss: 0.9639 - acc: 0.5652\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 0s 347us/step - loss: 0.9654 - acc: 0.6522\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 0s 606us/step - loss: 0.9795 - acc: 0.5652\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 0s 295us/step - loss: 0.9428 - acc: 0.5652\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 0s 350us/step - loss: 0.9852 - acc: 0.5652\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 0s 309us/step - loss: 0.9404 - acc: 0.6522\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 0s 547us/step - loss: 0.9047 - acc: 0.6087\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 0s 350us/step - loss: 0.9439 - acc: 0.5652\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 0s 247us/step - loss: 0.9097 - acc: 0.6522\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 0s 549us/step - loss: 0.9360 - acc: 0.6957\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 0s 285us/step - loss: 0.9156 - acc: 0.6522\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 0s 187us/step - loss: 0.9044 - acc: 0.6522\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 0s 417us/step - loss: 0.9033 - acc: 0.6087\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 0s 393us/step - loss: 0.8971 - acc: 0.6522\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 0s 362us/step - loss: 0.8848 - acc: 0.6522\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.8867 - acc: 0.6957\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 0s 338us/step - loss: 0.8645 - acc: 0.6522\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 0s 509us/step - loss: 0.9131 - acc: 0.6522\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 0s 536us/step - loss: 0.8258 - acc: 0.6957\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 0s 520us/step - loss: 0.9160 - acc: 0.6957\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 0s 184us/step - loss: 0.8336 - acc: 0.6957\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 0s 400us/step - loss: 0.8608 - acc: 0.6522\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 0s 221us/step - loss: 0.8315 - acc: 0.7826\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 0s 482us/step - loss: 0.8965 - acc: 0.6087\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 0s 307us/step - loss: 0.8221 - acc: 0.7391\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 0s 302us/step - loss: 0.8153 - acc: 0.7391\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 0s 175us/step - loss: 0.7870 - acc: 0.7391\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 0s 400us/step - loss: 0.7700 - acc: 0.7826\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 0s 380us/step - loss: 0.8477 - acc: 0.6522\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 0s 523us/step - loss: 0.8967 - acc: 0.7391\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 0s 399us/step - loss: 0.8344 - acc: 0.6522\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 0s 429us/step - loss: 0.8737 - acc: 0.6522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "23/23 [==============================] - 0s 230us/step - loss: 0.7344 - acc: 0.8696\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 0s 326us/step - loss: 0.7550 - acc: 0.7826\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 0s 568us/step - loss: 0.7648 - acc: 0.8261\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.7687 - acc: 0.7391\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 0s 430us/step - loss: 0.7484 - acc: 0.7826\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 0s 174us/step - loss: 0.7981 - acc: 0.7826\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 0s 304us/step - loss: 0.7741 - acc: 0.7826\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 0s 327us/step - loss: 0.7811 - acc: 0.6957\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 0s 523us/step - loss: 0.7114 - acc: 0.8261\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 0.7739 - acc: 0.8261\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 0s 276us/step - loss: 0.7420 - acc: 0.7826\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 0s 407us/step - loss: 0.8017 - acc: 0.7391\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 0s 243us/step - loss: 0.6880 - acc: 0.8696\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 0s 251us/step - loss: 0.7647 - acc: 0.7391\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 0s 280us/step - loss: 0.7206 - acc: 0.6957\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 0s 233us/step - loss: 0.6878 - acc: 0.8261\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 0s 268us/step - loss: 0.7222 - acc: 0.8261\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 0s 328us/step - loss: 0.7155 - acc: 0.6957\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 0s 388us/step - loss: 0.7419 - acc: 0.7391\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 0s 448us/step - loss: 0.7269 - acc: 0.7826\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 0s 316us/step - loss: 0.7029 - acc: 0.8261\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 0s 226us/step - loss: 0.6144 - acc: 0.8696\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 0s 309us/step - loss: 0.6248 - acc: 0.8696\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 0s 259us/step - loss: 0.6697 - acc: 0.8261\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 0s 132us/step - loss: 0.6728 - acc: 0.7826\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 0.6960 - acc: 0.7826\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 0s 408us/step - loss: 0.6256 - acc: 0.8261\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 0s 348us/step - loss: 0.6061 - acc: 0.8261\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 0s 349us/step - loss: 0.7015 - acc: 0.7391\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 0s 422us/step - loss: 0.6638 - acc: 0.8696\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 0s 286us/step - loss: 0.5973 - acc: 0.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa_core.policies.keras_policy:Done fitting keras policy model\n",
      "INFO:rasa_core.agent:Model directory models/dialogue exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa_core.agent:Persisted model to 'C:\\Users\\vanguiano\\Documents\\Projects\\conversational-interface\\models\\dialogue'\n"
     ]
    }
   ],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent(\"domain.yml\", policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "\n",
    "training_data = agent.load_data(\"data/stories.md\")\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split = 0.0,\n",
    "    epochs = 200)\n",
    "\n",
    "agent.persist(\"models/dialogue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying it all out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bot is ready to talk: Type your messages here or send 'stop'\n",
      "Hi, my name is James\n",
      "bye\n",
      "Bye!\n",
      "hi, my name is James\n",
      "Goodbye.\n",
      "hi, my name is Jack\n",
      "Talk to you later!\n",
      "hi, my name is Jack\n",
      "See you soon!\n",
      "hi, my name is Jack\n",
      "See you soon!\n"
     ]
    }
   ],
   "source": [
    "print(\"Your bot is ready to talk: Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for response in responses:\n",
    "        print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
